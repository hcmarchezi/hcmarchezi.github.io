{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Text Classification with Logistic Regression\"\n",
        "author: \"Humberto C Marchezi\"\n",
        "date: \"2023-07-28\"\n",
        "categories: [machine-learning]\n",
        "description: Text classification with logistic regression\n",
        "draft: true\n",
        "---"
      ],
      "id": "2fd69882"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "Logistics regression is a well known statistics tool for classification including text.\n",
        "The steps to implement a text classifier with this statistic tool will be explained here.\n",
        "\n",
        "## Training Flow\n",
        "\n",
        "\n",
        "```{mermaid}\n",
        "flowchart LR\n",
        "    A[Text] --> B[\"Feature_Extraction(T)\"]\n",
        "    B --> C[\"Prediction_Function(X)\"]\n",
        "    C --> D[\"Output Y^\"]\n",
        "    D --> E[\"Cost_Function(Y, Y^)\"]\n",
        "    E --> C\n",
        "```\n",
        "\n",
        "\n",
        "## Vocabulary & Feature Extraction\n",
        "\n",
        "### One-Hot-Encoding\n",
        "\n",
        "Consists of creating a vector of 0s and 1s (no other values) where each position represents a word in the vocabulary. If a word is present in a phrase (such a Twit) the corresponding position would be marked as 1 otherwise 0.\n",
        "\n",
        "* *Problem: Long training and prediction time:*\n",
        "It can get too big and sparse when a large vocabulary from many different texts are used. \n",
        "\n",
        "### Negative and Positive Frequencies\n",
        "\n",
        "The idea is to use feature vectors to count word frequencies for each prediction category (such as positive/negative in sentiment analysis). Global feature vector is calculated for each word, following the steps below:\n",
        "\n",
        "Map(word) ---> occurrence of that word in a given class \n",
        "\n",
        "|          | I | am | happy | sad | never |\n",
        "|----------|---|----|-------|-----|-------|\n",
        "| Positive | 2 | 2  | 1     | 0   | 0     |\n",
        "| Negative | 3 | 3  | 0     | 2   | 1     |\n",
        "\n",
        "## Preprocessing\n",
        "\n",
        "* **tokenization** - break text into array of words\n"
      ],
      "id": "c12bc7ca"
    },
    {
      "cell_type": "code",
      "metadata": {
        "md-indent": "    "
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer"
      ],
      "id": "b4f7cbea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* **stop words** - eliminate meaningless words (punctuation, articles, prepositions, not-important symbols, etc.)\n"
      ],
      "id": "ed617a83"
    },
    {
      "cell_type": "code",
      "metadata": {
        "md-indent": "    "
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "nltk.download(‘stopwords’)\n",
        "stopwords_english = stopwords.words(‘english’)\n",
        "punctuation = string.punctuation"
      ],
      "id": "5e86828c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* **stemming** - map word to its root form (remove ing, ed, etc.)\n"
      ],
      "id": "45a148f8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "md-indent": "    "
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_text = [ ]\n",
        "for word in text:\n",
        "stem_word = stemmer.stem(word)\n",
        "stemmed_text.append(stem_word)"
      ],
      "id": "3f1cba14",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* **lowercase** - convert all words to lowercase\n",
        "\n",
        "## Logistics Regression\n",
        "\n",
        "Linear Regression with Sigmoid function.\n",
        "$h(z) = 1 / ( 1 + e^{-z} )$  with  $z = \\theta^T x$                \n",
        "\n",
        "OR\n",
        "\n",
        "$sigmoid(x_0 \\theta_0 + x_1 \\theta_1 + x_2 \\theta_2 + x_3 \\theta_3)$\n",
        "\n",
        "## Training Workflow\n",
        "\n",
        ":::::::::::::: {.columns}\n",
        "::: {.column width=\"45%\"}\n",
        "\n",
        "\n",
        "```{mermaid}\n",
        "flowchart TD\n",
        "    A[\"&#952\"] --> B[\"h = h(X, &#952)\"]\n",
        "    B --> C[\"&#8711 = 1/m X^t (h - y)\"]\n",
        "    C --> D[\"&#952 = &#952 - &#945&#8711\"]\n",
        "    D --> E[\"J(&#952)\"]\n",
        "    E --> B\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        ":::\n",
        "::: {.column width=\"5%\"}\n",
        "\n",
        "\\\n",
        "\n",
        ":::\n",
        "::: {.column width=\"45%\"}\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "\n",
        "```{mermaid}\n",
        "flowchart TD\n",
        "    A[\"Initialize parameters\"] --> B[\"Classify/predict\"]\n",
        "    B --> C[\"Get gradient\"]\n",
        "    C --> D[\"Update\"]\n",
        "    D --> E[\"Get Loss\"]\n",
        "    E --> B\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        ":::\n",
        "::::::::::::::\n",
        "\n",
        "\n",
        "### Testing (with accuracy)\n",
        "\n",
        "Testing can be done via cross-validation data with $X_val$, $Y_val$ and $\\theta$ on the model to optimize hyper-parameters.\n",
        "\n",
        "\n",
        "* $X_val Y_val \\theta$\n",
        "    * $h(X_val . \\theta)$\n",
        "    * $pred = h(X_val . \\theta) >= 0.5$\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "0.3 \\\\\n",
        "0.8 \\\\\n",
        "0.5 \\\\\n",
        "\\vdots \\\\\n",
        "h_m\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ],
      "id": "82aee47d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}